{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle-GAN DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Requirements\n",
    "***\n",
    "### model files in '/cycle_demo'\n",
    "- cycle_gan.py\n",
    "- dataloader.py\n",
    "- networks.py\n",
    "- opt.py\n",
    "\n",
    "### datasets folders in './dataset/'\n",
    "- \"photo\": images/photos to be transfered \n",
    "- \"style\": style to transfer\n",
    "\n",
    "### Others\n",
    "- numpy\n",
    "- matplotlib\n",
    "- PyTorch\n",
    "\n",
    "### Model Checkpoints:\n",
    "Networks and Loss will be saved every 10 epochs in the folder \"saved_model_photo_style\"\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Demonstration of trained model\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cycle_demo as demo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with dataset\n",
    "This demo load the landscape dataset and Picasso in the dataset folder then train the model 100 epochs. The trained model is saved in './saved_models' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size = 1\n",
      "The number of training images = 1\n",
      "The number of style images = 1\n",
      "cuda\n",
      "No such file: ./saved_models/latest_net_GenA.pth\n",
      "No such file: ./saved_models/latest_net_GenB.pth\n",
      "No such file: ./saved_models/latest_net_DisA.pth\n",
      "No such file: ./saved_models/latest_net_DisB.pth\n",
      "latest_net_checkpoint.pth do not exist\n",
      "start new training\n",
      "End of epoch 1 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 2 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 3 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 4 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 5 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 6 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 7 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 8 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 9 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 10 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 11 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 12 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 13 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 14 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 15 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 16 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 17 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 18 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 19 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 20 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 21 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 22 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 23 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 24 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 25 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 26 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 27 / 100 \t Time Taken: 0 sec\n",
      "learning rate = 0.0002000\n"
     ]
    }
   ],
   "source": [
    "demo.training_model(model_path= './saved_models', dataset_path = './dataset', photo = 'landscape', style = 'picasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model\n",
    "It takes 30 mins to train the model with large size landscape dataset and style dataset. Here we provide a pre-trained model to demonstrate the result. The full-size dataset could be download from https://drive.google.com/drive/folders/1hQAO-faOqShCH0dV84Iwh0du2NoJFRDc?usp=sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = demo.load_trained_model(epo = 100)  # load the trained model\n",
    "dataset_loader = demo.load_dataset(dataset_path = './dataset', photo = 'landscape', style = 'picasso') # load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the forest photo into Picasso's style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "# style translation\n",
    "for i, (real_A, real_B) in enumerate(dataset_loader):\n",
    "    model.set_input(real_A.to(device), real_B.to(device))    \n",
    "    model.test()           # run inference\n",
    "    demo.plot_result(model) # show result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the sketch of ironman into colored comics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = demo.load_trained_model(photo = 'ironman', style = 'sketch', epo = 50)\n",
    "dataset_loader = demo.load_dataset(dataset_path = './dataset', photo = 'sketch', style = 'ironman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "for i, (real_A, real_B) in enumerate(dataset_loader):\n",
    "    model.set_input(real_A.to(device), real_B.to(device))    \n",
    "    model.test()           # run inference\n",
    "    demo.plot_result(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## present loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = model.load_checkpoint(opt.epoch)\n",
    "Loss = checkpoint['Loss']\n",
    "Loss = torch.stack(Loss).numpy()\n",
    "Loss = np.sum(Loss, axis = 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Evolution of Loss')\n",
    "plt.plot(Loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
