{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from cycle_gan import cycleGAN \n",
    "import opt\n",
    "import dataloader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size = 25\n",
      "The number of training images = 35\n",
      "The number of style images = 25\n",
      "cuda\n",
      "No such file: saved_models_mountain_small_paintings/latest_net_GenA.pth\n",
      "No such file: saved_models_mountain_small_paintings/latest_net_GenB.pth\n",
      "No such file: saved_models_mountain_small_paintings/latest_net_DisA.pth\n",
      "No such file: saved_models_mountain_small_paintings/latest_net_DisB.pth\n",
      "latest_net_checkpoint.pth do not exist\n",
      "start new training\n",
      "End of epoch 1 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 2 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 3 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 4 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 5 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 6 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 7 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 8 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 9 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 10\n",
      "End of epoch 10 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 11 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 12 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 13 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 14 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 15 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 16 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 17 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 18 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 19 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 20\n",
      "End of epoch 20 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 21 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 22 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 23 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 24 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 25 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 26 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 27 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 28 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 29 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 30\n",
      "End of epoch 30 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 31 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 32 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 33 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 34 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 35 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 36 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 37 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 38 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 39 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 40\n",
      "End of epoch 40 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 41 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 42 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 43 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 44 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 45 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 46 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 47 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 48 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 49 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 50\n",
      "End of epoch 50 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 51 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 52 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 53 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 54 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 55 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 56 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 57 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 58 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 59 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 60\n",
      "End of epoch 60 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 61 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 62 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 63 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 64 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 65 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 66 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 67 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 68 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 69 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 70\n",
      "End of epoch 70 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 71 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 72 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 73 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 74 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 75 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 76 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 77 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 78 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 79 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 80\n",
      "End of epoch 80 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 81 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 82 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 83 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 84 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 85 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 86 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 87 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 88 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 89 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 90\n",
      "End of epoch 90 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 91 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 92 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 93 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 94 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 95 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 96 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 97 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 98 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 99 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 100\n",
      "End of epoch 100 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 101 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 102 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 103 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 104 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 105 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 106 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 107 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 108 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 109 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "saving the model at the end of epoch 110\n",
      "End of epoch 110 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 111 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 112 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 113 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 114 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 115 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 116 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 117 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 118 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 119 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "saving the model at the end of epoch 120\n",
      "End of epoch 120 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 121 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 122 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 123 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n",
      "End of epoch 124 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0000200\n"
     ]
    }
   ],
   "source": [
    "dataset_path = opt.dataroot\n",
    "# mode is the name of image folders\n",
    "img_set = dataloader.GANTransDataset(dataset_path, mode = opt.set_A, image_size = opt.image_size)\n",
    "style_set = dataloader.GANTransDataset(dataset_path, mode = opt.set_B, image_size = opt.image_size)\n",
    "dataset = dataloader.GANCombinedDataset(img_set, style_set)\n",
    "img_size = len(img_set)    # get the number of images in the dataset.\n",
    "style_size = len(style_set)\n",
    "dataset_size = len(dataset)\n",
    "print('dataset size = %d' %dataset_size)\n",
    "print('The number of training images = %d' % img_size)\n",
    "print('The number of style images = %d' % style_size)\n",
    "\n",
    "model = cycleGAN(opt)      # create a model given opt.model and other options  \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.load_networks(opt.epoch)\n",
    "checkpoint = model.load_checkpoint(opt.epoch)\n",
    "# create dataloader \n",
    "dataset_loader = DataLoader(dataset, batch_size= 1, shuffle=True) # NEW CODE LINE\n",
    "\n",
    "start_epoch = checkpoint['current epoch'] + 1\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "    epoch_start_time = time.time()  # timer for entire epoch\n",
    "    loss_list = torch.zeros(8)\n",
    "    for i, (real_A,real_B) in enumerate(dataset_loader):  # inner loop within one epoch\n",
    "        model.set_input(real_A.to(device),real_B.to(device))         # unpack data from dataset and apply preprocessing\n",
    "        model.forward()\n",
    "        model.optimize_step()\n",
    "        loss_list += torch.Tensor(model.return_loss())\n",
    "    loss_list /= (i+1)\n",
    "    checkpoint['Loss'].append(loss_list)\n",
    "    checkpoint['current epoch']=epoch\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "        print('saving the model at the end of epoch %d' % (epoch))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "        model.save_checkpoint(checkpoint,'latest')\n",
    "        model.save_checkpoint(checkpoint, epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()                     # update learning rates at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = checkpoint['Loss']\n",
    "Loss_G = torch.stack(Loss).numpy()\n",
    "Loss_G = np.sum(Loss_G, axis = 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Evolution of Loss')\n",
    "plt.plot(Loss_G)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.savefig('Evolution_of_loss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
